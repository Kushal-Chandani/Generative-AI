{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tXVmV9HN7TsP",
        "outputId": "6bac9fdd-a8a8-4e15-e446-d422acfadc86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting guardrails-ai\n",
            "  Downloading guardrails_ai-0.6.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting boto3<2,>1 (from guardrails-ai)\n",
            "  Downloading boto3-1.36.21-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting coloredlogs<16.0.0,>=15.0.1 (from guardrails-ai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting diff-match-patch<20230431,>=20230430 (from guardrails-ai)\n",
            "  Downloading diff_match_patch-20230430-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting faker<26.0.0,>=25.2.0 (from guardrails-ai)\n",
            "  Downloading Faker-25.9.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting griffe<0.37.0,>=0.36.9 (from guardrails-ai)\n",
            "  Downloading griffe-0.36.9-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting guardrails-api-client<0.5.0,>=0.4.0a1 (from guardrails-ai)\n",
            "  Downloading guardrails_api_client-0.4.0a1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting guardrails-hub-types<0.0.5,>=0.0.4 (from guardrails-ai)\n",
            "  Downloading guardrails_hub_types-0.0.4-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting jsonref<2.0.0,>=1.1.0 (from guardrails-ai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (4.23.0)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from guardrails-ai) (0.3.35)\n",
            "Collecting litellm<2.0.0,>=1.37.14 (from guardrails-ai)\n",
            "  Downloading litellm-1.61.6-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting lxml<5.0.0,>=4.9.3 (from guardrails-ai)\n",
            "  Downloading lxml-4.9.4-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.30.1 in /usr/local/lib/python3.11/dist-packages (from guardrails-ai) (1.61.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 (from guardrails-ai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.24.0 (from guardrails-ai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk<2.0.0,>=1.24.0 (from guardrails-ai)\n",
            "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: pip>=22 in /usr/local/lib/python3.11/dist-packages (from guardrails-ai) (24.1.2)\n",
            "Requirement already satisfied: pydantic<3.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from guardrails-ai) (2.10.6)\n",
            "Collecting pydash<8.0.0,>=7.0.6 (from guardrails-ai)\n",
            "  Downloading pydash-7.0.7-py3-none-any.whl.metadata (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from guardrails-ai) (2.10.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from guardrails-ai) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from guardrails-ai) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.6.0 in /usr/local/lib/python3.11/dist-packages (from guardrails-ai) (13.9.4)\n",
            "Collecting rstr<4.0.0,>=3.2.2 (from guardrails-ai)\n",
            "  Downloading rstr-3.2.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting semver<4.0.0,>=3.0.2 (from guardrails-ai)\n",
            "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tenacity>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from guardrails-ai) (9.0.0)\n",
            "Collecting tiktoken>=0.5.1 (from guardrails-ai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: typer<0.16,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from typer[all]<0.16,>=0.9.0->guardrails-ai) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from guardrails-ai) (4.12.2)\n",
            "Collecting botocore<1.37.0,>=1.36.21 (from boto3<2,>1->guardrails-ai)\n",
            "  Downloading botocore-1.36.21-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>1->guardrails-ai)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3<2,>1->guardrails-ai)\n",
            "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs<16.0.0,>=15.0.1->guardrails-ai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting colorama>=0.4 (from griffe<0.37.0,>=0.36.9->guardrails-ai)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from guardrails-api-client<0.5.0,>=0.4.0a1->guardrails-ai) (75.1.0)\n",
            "Collecting urllib3<2.1.0,>=1.25.3 (from guardrails-api-client<0.5.0,>=0.4.0a1->guardrails-ai)\n",
            "  Downloading urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (0.22.3)\n",
            "Collecting fqdn (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (3.10)\n",
            "Collecting isoduration (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (3.0.0)\n",
            "Collecting rfc3339-validator (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3987 (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai)\n",
            "  Downloading rfc3987-1.3.8-py2.py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting uri-template (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=1.11 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (24.11.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (0.3.8)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (24.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (3.11.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (8.1.8)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (8.6.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (3.1.5)\n",
            "Collecting python-dotenv>=0.2.0 (from litellm<2.0.0,>=1.37.14->guardrails-ai)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (0.21.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (4.67.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.2.18)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.66.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-api~=1.15 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai)\n",
            "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.30.0->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-api~=1.15 (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai)\n",
            "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-sdk<2.0.0,>=1.24.0->guardrails-ai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting importlib-metadata>=6.8.0 (from litellm<2.0.0,>=1.37.14->guardrails-ai)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.0.0->guardrails-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.0.0->guardrails-ai) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->guardrails-ai) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->guardrails-ai) (3.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->guardrails-ai) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.6.0->guardrails-ai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14.0.0,>=13.6.0->guardrails-ai) (2.18.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->guardrails-ai) (2024.11.6)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<0.16,>=0.9.0->typer[all]<0.16,>=0.9.0->guardrails-ai) (1.5.4)\n",
            "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.17.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.37.14->guardrails-ai) (3.0.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->guardrails-ai) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->guardrails-ai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->guardrails-ai) (0.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->guardrails-ai) (0.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.18.3)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (0.28.1)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (2024.10.0)\n",
            "Downloading guardrails_ai-0.6.3-py3-none-any.whl (234 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.4/234.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.36.21-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diff_match_patch-20230430-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Faker-25.9.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-0.36.9-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading guardrails_api_client-0.4.0a1-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading guardrails_hub_types-0.0.4-py3-none-any.whl (36 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading litellm-1.61.6-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lxml-4.9.4-cp311-cp311-manylinux_2_28_x86_64.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.30.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydash-7.0.7-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.3/110.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rstr-3.2.2-py3-none-any.whl (10 kB)\n",
            "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.36.21-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading rfc3987-1.3.8-py2.py3-none-any.whl (13 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: rfc3987, urllib3, uri-template, types-python-dateutil, semver, rstr, rfc3339-validator, python-dotenv, pydash, protobuf, lxml, jsonref, jmespath, importlib-metadata, humanfriendly, guardrails-hub-types, fqdn, diff-match-patch, colorama, opentelemetry-proto, opentelemetry-api, griffe, faker, coloredlogs, botocore, arrow, tiktoken, s3transfer, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, isoduration, guardrails-api-client, opentelemetry-sdk, boto3, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, litellm, guardrails-ai\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 5.3.1\n",
            "    Uninstalling lxml-5.3.1:\n",
            "      Successfully uninstalled lxml-5.3.1\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "Successfully installed arrow-1.3.0 boto3-1.36.21 botocore-1.36.21 colorama-0.4.6 coloredlogs-15.0.1 diff-match-patch-20230430 faker-25.9.2 fqdn-1.5.1 griffe-0.36.9 guardrails-ai-0.6.3 guardrails-api-client-0.4.0a1 guardrails-hub-types-0.0.4 humanfriendly-10.0 importlib-metadata-8.5.0 isoduration-20.11.0 jmespath-1.0.1 jsonref-1.1.0 litellm-1.61.6 lxml-4.9.4 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-exporter-otlp-proto-http-1.30.0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 protobuf-5.29.3 pydash-7.0.7 python-dotenv-1.0.1 rfc3339-validator-0.1.4 rfc3987-1.3.8 rstr-3.2.2 s3transfer-0.11.2 semver-3.0.4 tiktoken-0.9.0 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0 urllib3-2.0.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "ddd3cf80cda3415fb405dc695f104017"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install guardrails-ai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!guardrails configure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCsx2XIBpvZY",
        "outputId": "a8aba332-6fd2-43f1-98bc-5f2416cecb48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Enable anonymous metrics reporting? [Y/n]: Y\n",
            "Do you wish to use remote inferencing? [Y/n]: n\n",
            "\n",
            "\u001b[1mEnter API Key below\u001b[0m\u001b[1m \u001b[0m👉 You can find your API Key at \u001b[4;94mhttps://hub.guardrailsai.com/keys\u001b[0m\n",
            "\n",
            "API Key: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJnaXRodWJ8OTcyNTQ4NDAiLCJhcGlLZXlJZCI6Ijk0ZWM1YTExLTZmMGQtNDMzNS04YTFmLTYyMTg2OGQzNmI5YSIsInNjb3BlIjoicmVhZDpwYWNrYWdlcyIsInBlcm1pc3Npb25zIjpbXSwiaWF0IjoxNzM5Njg5Njc4LCJleHAiOjQ4OTMyODk2Nzh9.cjDLW58kQoDMLQUfc71z_hu-2qyGSepuRZxIDhYp9gI\n",
            "\n",
            "            Login successful.\n",
            "\n",
            "            Get started by installing our RegexMatch validator:\n",
            "            https://hub.guardrailsai.com/validator/guardrails_ai/regex_match\n",
            "\n",
            "            You can install it by running:\n",
            "            guardrails hub install hub://guardrails/regex_match\n",
            "\n",
            "            Find more validators at https://hub.guardrailsai.com\n",
            "            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJnaXRodWJ8OTcyNTQ4NDAiLCJhcGlLZXlJZCI6Ijk0ZWM1YTExLTZmMGQtNDMzNS04YTFmLTYyMTg2OGQzNmI5YSIsInNjb3BlIjoicmVhZDpwYWNrYWdlcyIsInBlcm1pc3Npb25zIjpbXSwiaWF0IjoxNzM5Njg5Njc4LCJleHAiOjQ4OTMyODk2Nzh9.cjDLW58kQoDMLQUfc71z_hu-2qyGSepuRZxIDhYp9gI"
      ],
      "metadata": {
        "id": "K8iLNQ2hl0VH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!guardrails hub install hub://guardrails/toxic_language"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbCPVInlqmXR",
        "outputId": "b4483518-7e4c-4cd0-e53a-0916372d5318"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing hub:\u001b[35m/\u001b[0m\u001b[35m/guardrails/\u001b[0m\u001b[95mtoxic_language...\u001b[0m\n",
            "\u001b[2K\u001b[32m[ ===]\u001b[0m Fetching manifest\n",
            "\u001b[2K\u001b[32m[==  ]\u001b[0m Downloading dependencies\n",
            "\u001b[2K\u001b[32m[ ===]\u001b[0m Running post-install setup[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "\u001b[2K\u001b[32m[=== ]\u001b[0m Running post-install setup[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "\u001b[2K\u001b[32m[=   ]\u001b[0m Running post-install setupDownloading: \"https://github.com/unitaryai/detoxify/releases/download/v0.1.2/unbiased-albert-c8519128.ckpt\" to /root/.cache/torch/hub/checkpoints/unbiased-albert-c8519128.ckpt\n",
            "100% 44.6M/44.6M [00:00<00:00, 191MB/s]\n",
            "\u001b[2K\u001b[32m[   =]\u001b[0m Running post-install setup2025-02-16 09:23:03.459706: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2K\u001b[32m[====]\u001b[0m Running post-install setupWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739697783.816123    2756 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2K\u001b[32m[=== ]\u001b[0m Running post-install setupE0000 00:00:1739697783.906719    2756 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2K\u001b[32m[ ===]\u001b[0m Running post-install setup2025-02-16 09:23:04.516074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "config.json: 100% 684/684 [00:00<00:00, 3.88MB/s]\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 142kB/s]\n",
            "spiece.model: 100% 760k/760k [00:00<00:00, 11.0MB/s]\n",
            "tokenizer.json: 100% 1.31M/1.31M [00:00<00:00, 7.77MB/s]\n",
            "\u001b[2K\u001b[32m[   =]\u001b[0m Running post-install setup\n",
            "\u001b[1A\u001b[2K✅Successfully installed guardrails/toxic_language!\n",
            "\n",
            "\n",
            "\u001b[1mImport validator:\u001b[0m\n",
            "from guardrails.hub import ToxicLanguage\n",
            "\n",
            "\u001b[1mGet more info:\u001b[0m\n",
            "\u001b[4;94mhttps://hub.guardrailsai.com/validator/guardrails/toxic_language\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show guardrails-ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEDS-Extrrnx",
        "outputId": "f758cc86-bb7f-44b0-9bcb-9201e712b3e3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: guardrails-ai\n",
            "Version: 0.6.3\n",
            "Summary: Adding guardrails to large language models.\n",
            "Home-page: https://www.guardrailsai.com/\n",
            "Author: Guardrails AI\n",
            "Author-email: contact@guardrailsai.com\n",
            "License: Apache-2.0\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: boto3, coloredlogs, diff-match-patch, faker, griffe, guardrails-api-client, guardrails-hub-types, jsonref, jsonschema, langchain-core, litellm, lxml, openai, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-exporter-otlp-proto-http, opentelemetry-sdk, pip, pydantic, pydash, pyjwt, python-dateutil, requests, rich, rstr, semver, tenacity, tiktoken, typer, typing-extensions\n",
            "Required-by: guardrails-grhub-toxic-language\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Overview of the Notebook\n",
        "\n",
        "####This notebook demonstrates the use of the ToxicLanguage validator from the Guardrails AI package. The goal is to showcase how this validator can be used to detect and filter toxic or harmful language in text. By providing examples of both passing and failing cases, I aim to:\n",
        "\n",
        "####1. Understand the functionality of the ToxicLanguage validator.\n",
        "\n",
        "####2. Test its sensitivity by adjusting the threshold parameter.\n",
        "\n",
        "####3. Explore real-world applications, such as moderating user-generated content or enforcing community guidelines."
      ],
      "metadata": {
        "id": "jBcxNThx1FQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Guard and Validator\n",
        "import guardrails\n",
        "from guardrails.hub import ToxicLanguage\n",
        "from guardrails import Guard"
      ],
      "metadata": {
        "id": "ER2DwlXwrPMl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the Guard with the validator\n",
        "guard = Guard().use(\n",
        "    ToxicLanguage,\n",
        "    threshold=0.7,\n",
        "    validation_method=\"sentence\",\n",
        "    on_fail=\"exception\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EElIvlKDrPKD",
        "outputId": "b39585fd-179f-475d-d4ed-ba8726ac00ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Passing Examples"
      ],
      "metadata": {
        "id": "g2TdLdoT8OvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Positive and polite text\n",
        "text_pass_1 = \"Thank you for your help! I really appreciate it.\"\n",
        "try:\n",
        "    validated_pass_1 = guard.validate(text_pass_1)\n",
        "    print(\"Passed Validation:\", validated_pass_1)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuSrEMpz2Qn7",
        "outputId": "bbc526d5-2a4d-405a-f7b2-e4d33dee792f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/guardrails/validator_service/__init__.py:85: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Validation: ValidationOutcome(\n",
            "    call_id='134837953854464',\n",
            "    raw_llm_output='Thank you for your help! I really appreciate it.',\n",
            "    validation_summaries=[],\n",
            "    validated_output='Thank you for your help! I really appreciate it.',\n",
            "    reask=None,\n",
            "    validation_passed=True,\n",
            "    error=None\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Neutral and factual text\n",
        "text_pass_2 = \"The weather today is sunny and warm.\"\n",
        "try:\n",
        "    validated_pass_2 = guard.validate(text_pass_2)\n",
        "    print(\"Passed Validation:\", validated_pass_2)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFhFbfQQ8ENG",
        "outputId": "44c6c407-7116-4898-8181-71ec541d6c58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Validation: ValidationOutcome(\n",
            "    call_id='134837943114944',\n",
            "    raw_llm_output='The weather today is sunny and warm.',\n",
            "    validation_summaries=[],\n",
            "    validated_output='The weather today is sunny and warm.',\n",
            "    reask=None,\n",
            "    validation_passed=True,\n",
            "    error=None\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: Encouraging and supportive text\n",
        "text_pass_3 = \"You're doing a great job! Keep up the good work.\"\n",
        "try:\n",
        "    validated_pass_3 = guard.validate(text_pass_3)\n",
        "    print(\"Passed Validation:\", validated_pass_3)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izwICwSW8GNi",
        "outputId": "55d9fbcd-525f-4fb7-91f7-aa5a9bb28b54"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Validation: ValidationOutcome(\n",
            "    call_id='134837943117584',\n",
            "    raw_llm_output=\"You're doing a great job! Keep up the good work.\",\n",
            "    validation_summaries=[],\n",
            "    validated_output=\"You're doing a great job! Keep up the good work.\",\n",
            "    reask=None,\n",
            "    validation_passed=True,\n",
            "    error=None\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Failing Examples"
      ],
      "metadata": {
        "id": "qIFte-Em8Sl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 1: Insulting language\n",
        "text_fail_1 = \"You're such a useless idiot!\"\n",
        "try:\n",
        "    validated_fail_1 = guard.validate(text_fail_1)\n",
        "    print(\"Passed Validation:\", validated_fail_1)\n",
        "except Exception as e:\n",
        "    print(\"Validation Failed:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ3KFUUI2Qlx",
        "outputId": "57b0c3bd-8ced-49ff-86f2-d4a2656c03cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Failed: Validation failed for field with errors: The following sentences in your response were found to be toxic:\n",
            "\n",
            "- You're such a useless idiot!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Offensive language\n",
        "text_fail_2 = \"This is the worst piece of garbage I've ever seen.\"\n",
        "try:\n",
        "    validated_fail_2 = guard.validate(text_fail_2)\n",
        "    print(\"Passed Validation:\", validated_fail_2)\n",
        "except Exception as e:\n",
        "    print(\"Validation Failed:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqaVKRhE2Qi3",
        "outputId": "da7e55e8-f8eb-41d4-867a-532703e49826"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Failed: Validation failed for field with errors: The following sentences in your response were found to be toxic:\n",
            "\n",
            "- This is the worst piece of garbage I've ever seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: Hostile and aggressive language\n",
        "text_fail_3 = \"I can't believe how stupid you are. Get lost!\"\n",
        "try:\n",
        "    validated_fail_3 = guard.validate(text_fail_3)\n",
        "    print(\"Passed Validation:\", validated_fail_3)\n",
        "except Exception as e:\n",
        "    print(\"Validation Failed:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdMm54zj2Qf4",
        "outputId": "26f0417f-7c05-4456-c9de-ada0c51cf6ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Failed: Validation failed for field with errors: The following sentences in your response were found to be toxic:\n",
            "\n",
            "- I can't believe how stupid you are.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comments\n",
        "1. Passing Examples: Polite and neutral text passed validation, confirming the validator's ability to identify non-toxic content.\n",
        "2. Failing Examples: Toxic language triggered exceptions, demonstrating effective filtering of harmful content.\n",
        "3. Threshold Sensitivity: A 0.7 threshold balances flagging moderately toxic content while allowing borderline cases."
      ],
      "metadata": {
        "id": "t8gVGlUs8Yix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Why you chose this particular validator (technical or practical reasons).\n",
        "\n",
        "Ans: I chose the Toxic Language validator because of its ability to accurately detect toxic or harmful language at the sentence level ensures precise identification of problematic content, which is crucial for maintaining safe environments. Additionally, it also addresses the growing need to filter out toxic language in user-generated content, providing a reliable solution to a important issue."
      ],
      "metadata": {
        "id": "Vk25tRCU-SUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##How the validator addresses a specific risk (e.g., preventing the spread of offensive content, avoiding data leakage, etc.).\n",
        "\n",
        "Ans: By identifying and blocking toxic language before it reaches end-users, it helps prevent harassment, uphold community standards, and safeguard brand reputations. This approach ensures that digital spaces, that we are part of, remain respectful and compliant with ethical guidelines."
      ],
      "metadata": {
        "id": "wMrdODdx_GRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Real-World Applications:\n",
        "\n",
        "1. Maintaining Safe User Interactions: Validators filter toxic language from user content to keep platforms safe and inclusive.\n",
        "\n",
        "2. Protecting Brand Reputation: Validators block offensive posts to safeguard brand image and maintain trust.\n",
        "\n",
        "3. Ensuring Compliance with Regulations: Validators ensure content aligns with regulations by flagging prohibited material.\n"
      ],
      "metadata": {
        "id": "Uo4wgLbJBfuQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Additonal Exploration"
      ],
      "metadata": {
        "id": "jbyte0iECTKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using valudation_method=full which validates the entire text as a single unit."
      ],
      "metadata": {
        "id": "31iyt8-NCcAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "guard_full = Guard().use(\n",
        "    ToxicLanguage,\n",
        "    threshold=0.5,\n",
        "    validation_method=\"full\",\n",
        "    on_fail=\"exception\"\n",
        ")\n",
        "\n",
        "# Test with mixed text\n",
        "text_mixed = \"You're doing great! But sometimes you can be really frustrating.\"\n",
        "try:\n",
        "    validated_full = guard_full.validate(text_mixed)\n",
        "    print(\"Passed Validation (Full Validation):\", validated_full)\n",
        "except Exception as e:\n",
        "    print(\"Validation Failed (Full Validation):\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZPs9jlaBh8x",
        "outputId": "75fbf274-bcf1-40d6-b99f-51f0ad21e555"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed Validation (Full Validation): ValidationOutcome(\n",
            "    call_id='134837936277376',\n",
            "    raw_llm_output=\"You're doing great! But sometimes you can be really frustrating.\",\n",
            "    validation_summaries=[],\n",
            "    validated_output=\"You're doing great! But sometimes you can be really frustrating.\",\n",
            "    reask=None,\n",
            "    validation_passed=True,\n",
            "    error=None\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##References\n",
        "\n",
        "1. https://hub.guardrailsai.com/validator/guardrails/toxic_language"
      ],
      "metadata": {
        "id": "KvjEs47ZANIJ"
      }
    }
  ]
}