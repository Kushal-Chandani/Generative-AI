{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "name": "LSTM_Deep_Dive_Dr_Adnan_Masood",
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q3CgaJvvsow"
      },
      "source": [
        "#################################################################\n",
        "#                                                               #\n",
        "#  CS435 Generative AI: Security, Ethics and Governance         #\n",
        "#                                                               #\n",
        "#  Instructor: Dr. Adnan Masood                                 #\n",
        "#  Contact:    adnanmasood@gmail.com                            #\n",
        "#                                                               #\n",
        "#  Notebook is MIT Licensed                                     #\n",
        "#################################################################\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "6q3CgaJvvsow"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h-Z7FeSvsoy"
      },
      "source": [
        "# Long Short-Term Memory (LSTM) Networks\n",
        "\n",
        "Welcome to our session on **Long Short-Term Memory (LSTM)** networks!\n",
        "\n",
        "In this Jupyter notebook, we will explore LSTMs at **five different levels** of explanation (from simpler to advanced), while providing code samples, equations, examples, and exercises. This notebook is structured so you can **run each code cell** and see how it works for yourself.\n",
        "\n",
        "## Building an Intuitive Understanding\n",
        "\n",
        "We will then cover:\n",
        "- **Intuition behind the technology**\n",
        "- **History and invention of LSTM**\n",
        "- **Illustrative examples with code**\n",
        "- **Example calculations** (weights, biases, gates)\n",
        "- **Step-by-step example from scratch**\n",
        "- **Illustrative problem** LSTMs solve\n",
        "- **Real-world problem** LSTMs solve\n",
        "- **Questions to ponder**\n",
        "- **Answers** with code examples\n",
        "- **TODO code sample** with hints\n",
        "- **Glossary** of important terms\n"
      ],
      "id": "6h-Z7FeSvsoy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcBZr5bnvsoz"
      },
      "source": [
        "Imagine you have a special notepad that can remember important things and forget unimportant things. That’s what an **LSTM** (Long Short-Term Memory) is for a computer.\n",
        "\n",
        "- A normal computer tries to remember everything, but that can be overwhelming.\n",
        "- An LSTM decides what to keep, what to throw away, and what to use right now.\n",
        "\n",
        "This helps when you want a machine to learn from things that happen in a sequence—like **words in a sentence**, **notes in a song**, or **data points in a time series**. The LSTM is good at handling important memories from the past, while forgetting stuff that’s not important."
      ],
      "id": "DcBZr5bnvsoz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqzfUiVIvsoz"
      },
      "source": [
        "### Intuition Behind LSTM\n",
        "Think of an LSTM as a **smart filter** for remembering and forgetting information:\n",
        "1. It looks at new information.\n",
        "2. It looks at what it already knows.\n",
        "3. It decides **“Should I remember this new piece of information or forget it?”**\n",
        "4. It also decides **“How much of the old memory should I keep?”**\n",
        "\n",
        "LSTMs are used for all sorts of tasks involving sequences:\n",
        "- **Text generation** (Predicting the next word)\n",
        "- **Sentiment analysis** (Reading a tweet or sentence and deciding if it’s positive or negative)\n",
        "- **Time series forecasting** (Predicting stock prices or weather based on past data)\n",
        "- **Speech recognition** (Understanding spoken words)\n",
        "\n",
        "### A Brief History\n",
        "- **1997**: LSTM was introduced by **Sepp Hochreiter and Jürgen Schmidhuber**.\n",
        "- It was invented because older models, known as **RNNs (Recurrent Neural Networks)**, had trouble remembering information for more than a few steps (known as the **vanishing gradient** problem).\n",
        "- LSTMs added a clever architecture to fix that problem by using **gates** to manage information.\n"
      ],
      "id": "KqzfUiVIvsoz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgGDbB2Xvsoz"
      },
      "source": [
        "### Underlying Technology (How LSTM Works)\n",
        "An LSTM is a special type of Recurrent Neural Network (RNN) cell. In a regular RNN, we have:\n",
        "```\n",
        "h_t = tanh(W_h * [h_{t-1}, x_t] + b_h)\n",
        "```\n",
        "Where:\n",
        "- **h_t** is the hidden state at time step **t**.\n",
        "- **x_t** is the input at time step **t**.\n",
        "- **W_h** and **b_h** are parameters (weights and biases).\n",
        "\n",
        "But in an LSTM cell, we introduce something called the **cell state**, denoted as **C_t**. The cell state is like a conveyor belt that can carry information from the past to the future. The LSTM can add or remove information from the cell state using **gates**.\n",
        "\n",
        "### Three Main Gates in an LSTM\n",
        "1. **Forget Gate ($f_t$)**: Decides what information to **forget** from the cell state.\n",
        "2. **Input Gate ($i_t$)**: Decides what new information to store in the cell state.\n",
        "3. **Output Gate ($o_t$)**: Decides what information from the cell state we will **output** at this time step.\n",
        "\n",
        "Additionally, there's a candidate cell state update $\\tilde{C}_t$ which is proposed new information to add into the cell.\n",
        "\n",
        "So at each time step **t**:\n",
        "\n",
        "1. We read the input **x_t** and previous hidden state **h_{t-1}**.\n",
        "2. We compute the **forget gate**: how much of the previous cell state **C_{t-1}** do we keep?\n",
        "3. We compute the **input gate**: how much new information (candidate) do we add?\n",
        "4. We update the cell state **C_t**.\n",
        "5. We compute the **output gate**: how much of the new cell state do we reveal as the new hidden state **h_t**?\n"
      ],
      "id": "fgGDbB2Xvsoz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08Hq4rXcvso0"
      },
      "source": [
        "### Mathematical Details of LSTM\n",
        "\n",
        "Below are the key LSTM equations. Each gate is a function of the current input $x_t$ and the previous hidden state $h_{t-1}$. We typically group them together as $[h_{t-1}, x_t]$ when we multiply by the respective weight matrices.\n",
        "\n",
        "1. **Forget Gate**: $f_t$\n",
        "$$\n",
        "f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)\n",
        "$$\n",
        "Here, $f_t$ ranges between 0 and 1, indicating how much of the old cell state you keep.\n",
        "\n",
        "2. **Input Gate**: $i_t$\n",
        "$$\n",
        "i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)\n",
        "$$\n",
        "This gate controls how much new information gets stored in the cell state.\n",
        "\n",
        "3. **Candidate Cell State**: $\\tilde{C}_t$\n",
        "$$\n",
        "\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)\n",
        "$$\n",
        "This is the new information (candidate) that could be added to the cell state.\n",
        "\n",
        "4. **New Cell State**: $C_t$\n",
        "$$\n",
        "C_t = f_t \\odot C_{t-1} + i_t \\odot \\tilde{C}_t\n",
        "$$\n",
        "The new cell state is a combination of the old state (scaled by the forget gate) and the candidate state (scaled by the input gate).\n",
        "\n",
        "5. **Output Gate**: $o_t$\n",
        "$$\n",
        "o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)\n",
        "$$\n",
        "This decides how much of the cell state to output.\n",
        "\n",
        "6. **New Hidden State**: $h_t$\n",
        "$$\n",
        "h_t = o_t \\odot \\tanh(C_t)\n",
        "$$\n",
        "\n",
        "### Explanation of Terms\n",
        "- $W_f, W_i, W_C, W_o$: Weight matrices for forget, input, candidate, and output.\n",
        "- $b_f, b_i, b_C, b_o$: Biases for forget, input, candidate, and output.\n",
        "- $\\sigma$: Sigmoid function (outputs between 0 and 1).\n",
        "- $\\tanh$: Hyperbolic tangent function (outputs between -1 and 1).\n",
        "- $\\odot$: Element-wise multiplication.\n",
        "\n",
        "### Example Calculations\n",
        "Let’s assume for a particular time step:\n",
        "- **h_{t-1}** = [0.2, 0.4]\n",
        "- **x_t** = [0.6, 0.1]\n",
        "- Weights (W_f, W_i, etc.) are some matrices we multiply.\n",
        "- Biases are added.\n",
        "1. We compute $[h_{t-1}, x_t]$ = [0.2, 0.4, 0.6, 0.1]\n",
        "2. Multiply by a weight matrix (for example, W_f) and add b_f.\n",
        "3. Apply the sigmoid function to get a value between 0 and 1.\n",
        "4. That value decides how much of the old cell state to keep.\n",
        "\n",
        "By repeating this for input gate, candidate, and output gate, we systematically update our hidden state and cell state.\n"
      ],
      "id": "08Hq4rXcvso0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQZGngouvso0"
      },
      "source": [
        "At this advanced level, we delve into **research directions**:\n",
        "- **Variants of LSTM**: GRU (Gated Recurrent Unit), Peephole LSTM, BiLSTM, etc.\n",
        "- **Optimization Challenges**: How to properly initialize weights, choose learning rates, etc.\n",
        "- **Regularization**: Dropout in RNNs, recurrent dropout.\n",
        "- **Applications**: advanced language models, speech recognition, video analysis.\n",
        "- **Questions**: How do we interpret cell states in tasks like sentiment analysis? How do we reduce complexity for large vocabularies?\n",
        "\n",
        "You can ask questions such as:\n",
        "1. *How do you handle very long sequences without losing information?*\n",
        "2. *What happens if the forget gate is always close to 1?*\n",
        "3. *How do we interpret attention mechanisms in the context of LSTM-based architectures?*\n",
        "4. *When should we prefer GRU over LSTM?*\n",
        "5. *How do we visualize the internal states to gain interpretability?*\n",
        "\n",
        "We will provide some short answers and code examples to illustrate these soon.\n"
      ],
      "id": "TQZGngouvso0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMJAghOrvso1"
      },
      "source": [
        "# Step-by-Step Example: Building an LSTM from Scratch\n",
        "\n",
        "Below is a simplified example (a demonstration, not a full training pipeline on a large dataset) to show how you might build an LSTM cell from scratch. We’ll use Python and NumPy to illustrate the core ideas. This is just to build intuition; in practice, libraries like PyTorch or TensorFlow handle these details for you."
      ],
      "id": "MMJAghOrvso1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htt4oio6vso1",
        "outputId": "a0a92977-f0f7-425b-8361-072fa5038ad2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Initialize random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Let's define the input dimension (x_t) and hidden dimension (h_t)\n",
        "input_dim = 3  # for example\n",
        "hidden_dim = 2\n",
        "\n",
        "# Initialize weight matrices for forget, input, candidate, output\n",
        "W_f = np.random.randn(hidden_dim, hidden_dim + input_dim)\n",
        "W_i = np.random.randn(hidden_dim, hidden_dim + input_dim)\n",
        "W_c = np.random.randn(hidden_dim, hidden_dim + input_dim)\n",
        "W_o = np.random.randn(hidden_dim, hidden_dim + input_dim)\n",
        "\n",
        "# Initialize biases\n",
        "b_f = np.random.randn(hidden_dim, 1)\n",
        "b_i = np.random.randn(hidden_dim, 1)\n",
        "b_c = np.random.randn(hidden_dim, 1)\n",
        "b_o = np.random.randn(hidden_dim, 1)\n",
        "\n",
        "# Initial hidden state h_{t-1} and cell state C_{t-1}\n",
        "h_prev = np.zeros((hidden_dim, 1))\n",
        "C_prev = np.zeros((hidden_dim, 1))\n",
        "\n",
        "# Single time-step forward pass of LSTM\n",
        "def lstm_step(x_t, h_prev, C_prev):\n",
        "    # Combine h_{t-1} and x_t\n",
        "    concat = np.vstack((h_prev, x_t))  # shape: (hidden_dim + input_dim, 1)\n",
        "\n",
        "    # Forget gate\n",
        "    f_t = sigmoid(np.dot(W_f, concat) + b_f)  # shape: (hidden_dim, 1)\n",
        "\n",
        "    # Input gate\n",
        "    i_t = sigmoid(np.dot(W_i, concat) + b_i)  # shape: (hidden_dim, 1)\n",
        "\n",
        "    # Candidate cell state\n",
        "    C_tilde = tanh(np.dot(W_c, concat) + b_c)  # shape: (hidden_dim, 1)\n",
        "\n",
        "    # New cell state\n",
        "    C_t = f_t * C_prev + i_t * C_tilde\n",
        "\n",
        "    # Output gate\n",
        "    o_t = sigmoid(np.dot(W_o, concat) + b_o)  # shape: (hidden_dim, 1)\n",
        "\n",
        "    # New hidden state\n",
        "    h_t = o_t * tanh(C_t)\n",
        "\n",
        "    return h_t, C_t\n",
        "\n",
        "# Example input x_t of shape (input_dim, 1)\n",
        "x_t = np.array([[0.5], [0.1], [0.9]])\n",
        "\n",
        "h_next, C_next = lstm_step(x_t, h_prev, C_prev)\n",
        "print('New hidden state (h_next):\\n', h_next)\n",
        "print('\\nNew cell state (C_next):\\n', C_next)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New hidden state (h_next):\n",
            " [[-0.07794162]\n",
            " [-0.06642324]]\n",
            "\n",
            "New cell state (C_next):\n",
            " [[-0.1448926 ]\n",
            " [-0.12589963]]\n"
          ]
        }
      ],
      "id": "Htt4oio6vso1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLYCZ9a0vso2"
      },
      "source": [
        "Running the cell above will give you a sense of how the LSTM cell updates from one time step to the next, using the random weights and biases we created.\n",
        "\n",
        "## Illustrative Problem LSTMs Solve\n",
        "A classic example is **predicting the next word in a sentence**. The LSTM sees a sequence of words (converted to numbers), then it tries to predict the next word. Over many examples, it learns patterns in language.\n",
        "\n",
        "## Real-world Problem\n",
        "A very common real-world problem is **time series forecasting** for sales, stock prices, or even electricity consumption. LSTMs are well-suited because they can remember crucial patterns over time.\n",
        "\n",
        "### How to Solve a Real-World Problem Using LSTMs\n",
        "1. **Collect data**: e.g., daily stock prices over the past five years.\n",
        "2. **Preprocess**: scale values, create sequences of input data (e.g., the past 60 days as input to predict the next day).\n",
        "3. **Build an LSTM model** (using TensorFlow or PyTorch).\n",
        "4. **Train the model** on historical data.\n",
        "5. **Evaluate** on unseen data and measure error.\n",
        "6. **Deploy** or use the model to forecast future values.\n",
        "\n",
        "## Questions to Illustrate the Use of LSTM\n",
        "1. **Why do we need gates in LSTM?**\n",
        "2. **How does the forget gate help fix the vanishing gradient problem?**\n",
        "3. **What is the difference between an LSTM and a GRU?**\n",
        "4. **When might you choose a simple RNN over an LSTM?**\n",
        "5. **What are some ways to regularize an LSTM to prevent overfitting?**\n",
        "\n",
        "## Short Answers\n",
        "1. *We need gates to control how much information flows in and out of the cell state, solving the memory and forgetting mechanisms.*\n",
        "2. *The forget gate scales the old memory, allowing it to pass information over many timesteps without being multiplied by small numbers repeatedly.*\n",
        "3. *A GRU (Gated Recurrent Unit) has fewer gates (just reset and update), making it slightly simpler and sometimes faster to train.*\n",
        "4. *For short sequences with minimal long-range dependencies, a simple RNN can work and is faster.*\n",
        "5. *You can use dropout between layers, recurrent dropout, or L2 regularization on weights.*\n"
      ],
      "id": "hLYCZ9a0vso2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZpNSpZevso2"
      },
      "source": [
        "## A Sample Exercise\n",
        "\n",
        "Now let’s build a simple LSTM for a **toy sequence prediction** problem using **TensorFlow/Keras**. We’ll create a small dataset and ask students to complete some TODO items.\n"
      ],
      "id": "BZpNSpZevso2"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qviu8iLLki8q",
        "outputId": "c52fcd76-8890-4669-cbb2-2a2066d21440"
      },
      "id": "Qviu8iLLki8q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfocfnuGvso2",
        "outputId": "a01460c9-13c2-47ed-ffa2-941b48fa8bf7"
      },
      "source": [
        "#@title Imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "print(tf.__version__)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "id": "ZfocfnuGvso2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD4CvSfxvso2"
      },
      "source": [
        "### Create a Toy Dataset\n",
        "We’ll create a simple time-series dataset where the **input** is a sequence of numbers and the **target** is the next number in the sequence. For example:\n",
        "```\n",
        "Input sequence: [0, 1, 2]\n",
        "Target: 3\n",
        "```\n",
        "```\n",
        "Input sequence: [1, 2, 3]\n",
        "Target: 4\n",
        "```\n",
        "And so on.\n"
      ],
      "id": "BD4CvSfxvso2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XmeWfuYvso2",
        "outputId": "3f62e490-8557-42df-e180-79dfa5859549"
      },
      "source": [
        "# Define sequence length and create data\n",
        "sequence_length = 3\n",
        "data = np.array(range(30))  # 0 to 29\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(len(data) - sequence_length):\n",
        "    X.append(data[i:i+sequence_length])\n",
        "    y.append(data[i+sequence_length])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"Sample X:\", X[:5])\n",
        "print(\"Sample y:\", y[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (27, 3)\n",
            "y shape: (27,)\n",
            "Sample X: [[0 1 2]\n",
            " [1 2 3]\n",
            " [2 3 4]\n",
            " [3 4 5]\n",
            " [4 5 6]]\n",
            "Sample y: [3 4 5 6 7]\n"
          ]
        }
      ],
      "id": "3XmeWfuYvso2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHk3zezwvso2"
      },
      "source": [
        "### Reshape for LSTM Input\n",
        "Keras LSTMs expect a 3D input of shape: `(batch_size, timesteps, features)`. Here, our `features` = 1 (since we only have one value at each timestep)."
      ],
      "id": "VHk3zezwvso2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0oi1bOxvso2",
        "outputId": "6a062c53-c6bc-4eaf-f78e-17f8ae40a311"
      },
      "source": [
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "print(\"Reshaped X:\", X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped X: (27, 3, 1)\n"
          ]
        }
      ],
      "id": "t0oi1bOxvso2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olKpfSONvso2"
      },
      "source": [
        "### Build an LSTM Model\n",
        "\n",
        "#### TODO:\n",
        "1. Change the number of LSTM units to 10.\n",
        "2. Add another Dense layer.\n",
        "3. Compile with a different optimizer (like `tf.keras.optimizers.Adam(learning_rate=0.01)`).\n",
        "\n",
        "Hints:\n",
        "- You can add more layers by doing `model.add(Dense( ... ))`.\n",
        "- You can set the learning rate in the Adam optimizer: `Adam(learning_rate=0.01)`.\n"
      ],
      "id": "olKpfSONvso2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "giFPSLAavso2",
        "outputId": "dedb3500-0aad-4589-9e44-ecc5647515f5"
      },
      "source": [
        "model = Sequential()\n",
        "# TODO 1: Increase LSTM units from 5 to 10\n",
        "model.add(LSTM(10, input_shape=(sequence_length, 1)))  # <-- Replace 5 with 10\n",
        "\n",
        "# TODO 2: Optionally add another Dense layer\n",
        "model.add(Dense(6))\n",
        "model.add(Dense(6))\n",
        "model.add(Dense(1))\n",
        "model.add(Dense(1))\n",
        "\n",
        "\n",
        "# TODO 3: Compile with a different optimizer and learning rate\n",
        "model.compile(loss='mse', optimizer=Adam(learning_rate=0.09))  # <-- Replace 'adam' with Adam(...) for new LR\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m66\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m42\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m7\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m2\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m597\u001b[0m (2.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597</span> (2.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m597\u001b[0m (2.33 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">597</span> (2.33 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "id": "giFPSLAavso2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8oDuFXdvso2"
      },
      "source": [
        "### Train the Model\n"
      ],
      "id": "L8oDuFXdvso2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "U8_4xM2Jvso3",
        "outputId": "f03152f5-7c9a-45fd-f8be-39293cc2122d"
      },
      "source": [
        "history = model.fit(X, y, epochs=100, verbose=0)\n",
        "print(\"Training complete!\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "id": "U8_4xM2Jvso3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwynX0Omvso3"
      },
      "source": [
        "### Test the Model\n",
        "Let’s predict what comes after the sequence `[27, 28, 29]` (the last few in our training data) and see if it predicts **30**.\n"
      ],
      "id": "RwynX0Omvso3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxFLYmVtvso3",
        "outputId": "fdf34d79-70e7-417f-b4ea-67d4419415f2"
      },
      "source": [
        "test_seq = np.array([[27], [28], [29]])\n",
        "test_seq = test_seq.reshape((1, sequence_length, 1))\n",
        "prediction = model.predict(test_seq)\n",
        "print(\"Predicted next number:\", prediction[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c5c8df09620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step\n",
            "Predicted next number: 29.636183\n"
          ]
        }
      ],
      "id": "fxFLYmVtvso3"
    },
    {
      "cell_type": "code",
      "source": [
        "#Tried differernt parameters closest i could get is 29.63"
      ],
      "metadata": {
        "id": "qUSu_wylmmML"
      },
      "id": "qUSu_wylmmML",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWCRjiDavso3"
      },
      "source": [
        "## Glossary\n",
        "- **RNN**: Recurrent Neural Network; processes sequences by iterating through timesteps.\n",
        "- **LSTM**: Long Short-Term Memory network; a special RNN with gates to remember or forget.\n",
        "- **Cell State (C)**: The long-term memory that flows through time.\n",
        "- **Hidden State (h)**: The short-term output from the LSTM cell at each time step.\n",
        "- **Forget Gate**: Gate that decides what to remove from the cell state.\n",
        "- **Input Gate**: Gate that decides what to add to the cell state.\n",
        "- **Output Gate**: Gate that decides what to reveal as the hidden state.\n",
        "- **Sigmoid ($\\sigma$)**: A function that outputs between 0 and 1.\n",
        "- **Tanh ($\\tanh$)**: A function that outputs between -1 and 1.\n",
        "- **Weights (W)**, **Biases (b)**: Learnable parameters that the network updates via backpropagation.\n",
        "- **Vanishing Gradient Problem**: When gradients become very small, making it hard to learn long-term dependencies.\n",
        "- **GRU**: Gated Recurrent Unit, a simpler variant of LSTM.\n"
      ],
      "id": "DWCRjiDavso3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gXr4ojTvso3"
      },
      "source": [
        "## Conclusion\n",
        "You have now:\n",
        "- Learned the **intuition** behind LSTMs.\n",
        "- Seen the **mathematical equations**.\n",
        "- Walked through a **from-scratch** example in NumPy.\n",
        "- Built a **toy LSTM** model in TensorFlow/Keras.\n",
        "- Explored **practical usage**, real-world examples, and Q&A.\n",
        "\n",
        "Feel free to experiment with:\n",
        "- Different numbers of LSTM units.\n",
        "- More layers.\n",
        "- Different optimizers.\n",
        "- New data.\n",
        "\n",
        "Keep asking questions and exploring more advanced topics like **attention mechanisms**, **transformers**, and **sequence-to-sequence models**!"
      ],
      "id": "0gXr4ojTvso3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yllKnmvSvso3",
        "outputId": "7b03df64-d043-4122-d027-2ba4ed1553d6"
      },
      "source": [
        "import os, sys, platform, datetime, uuid, socket\n",
        "\n",
        "def signoff(name=\"Anonymous\"):\n",
        "    colab_check = \"Yes\" if 'google.colab' in sys.modules else \"No\"\n",
        "    mac_addr = ':'.join(format((uuid.getnode() >> i) & 0xff, '02x') for i in reversed(range(0, 48, 8)))\n",
        "    print(\"+++ Acknowledgement +++\")\n",
        "    print(f\"Executed on: {datetime.datetime.now()}\")\n",
        "    print(f\"In Google Colab: {colab_check}\")\n",
        "    print(f\"System info: {platform.system()} {platform.release()}\")\n",
        "    print(f\"Node name: {platform.node()}\")\n",
        "    print(f\"MAC address: {mac_addr}\")\n",
        "    try:\n",
        "        print(f\"IP address: {socket.gethostbyname(socket.gethostname())}\")\n",
        "    except:\n",
        "        print(\"IP address: Unknown\")\n",
        "    print(f\"Signing off, {name}\")\n",
        "\n",
        "signoff(\"Kushal Chandani\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+++ Acknowledgement +++\n",
            "Executed on: 2025-02-02 16:59:53.795183\n",
            "In Google Colab: Yes\n",
            "System info: Linux 6.1.85+\n",
            "Node name: d4d087cbffc2\n",
            "MAC address: 02:42:ac:1c:00:0c\n",
            "IP address: 172.28.0.12\n",
            "Signing off, Kushal Chandani\n"
          ]
        }
      ],
      "id": "yllKnmvSvso3"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3PU5A0QhjrQw"
      },
      "id": "3PU5A0QhjrQw",
      "execution_count": null,
      "outputs": []
    }
  ]
}